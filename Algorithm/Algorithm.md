# 알고리즘

코딩 테스트 통과 및 컴퓨팅 사고능력을 기르기 위해 학습

---

## 목차
1. [개요](#1.-개요)
2. 문제 해결 시작하기
3. 알고리즘 분석
    - 시간 복잡도 분석
    - 정당성 증명
4. 알고리즘 설계 패러다임
    - [무식하게 풀기](#1.-무식하게-풀기)
    - [분할 정복](#2.-분할-정복)
    - [동적 계획법](#3.-동적-계획법)
    - 탐욕법
5. 유명한 알고리즘들
    - [정수론](#1.-정수론)
6. 기초 자료 구조
    - 비트마스트
    - 부분 합
    - 선형 자료 구조
    - 큐, 스택, 데크
7. 트리
    - [트리의 구현과 순회](#1.-트리의-구현과-순회)
    - [이진 검색 트리](#2.-이진-검색-트리)
    - [우선순위 큐와 힙](#3.-우선순위-큐와-힙)
    - [구간 트리](#4.-구간-트리)
    - [상호 배타적 집합](#5.-상호-배타적-집합)
8. 그래프
    - [그래프의 표현과 정의](#1.-그래프의-표현과-정의)
    - [DFS](#2.-그래프의-깊이-우선-탐색(DFS))
    - [BFS](#3.-그래프-너비-우선-탐색(BFS))
    - 최단 경로 알고리즘
    - 최소 스패닝 틜
    - 네트워크 유량

---

---
## 1. 개요
---
### 알고리즘을 잘하기 위한 3요소
1. 구현력
    내가 생각한 알고리즘을 그대로 소스코드로 구현하는 과정  
    구현력 부족 시 대충 어떻게 하라는지는 알지만 코딩은 막힘  
    → 내가 어떤 프로그램을 만들고자 하는지를 명확히!  
    → 무엇을 입력받아 어디에 저장하고 어떤 과정을 거쳐 중간결과와 최종 결과물은 어떤 것인지 파악    
    순서도 그리는 연습!
2. 문제해결능력  
    문제해결능력 부족시 어떻게 접근해야 할지 모름   
    → 양질의 문제를(30~2시간 이내에 고민 및 해결 가능한 문제)를 풀고 이미 풀어본 문제들을 정리  
3. 배경지식 
    기초적인 수학지식을 의미    
    코딩 문법, 시,공간 복잡도 분석, 자료구조(배열, 트리, 그래프, 힙, BST, 스택, 큐), 기초 알고리즘(DFS, BFS, 정렬, 백트래킹, DP, 분할정복, 최단거리)    
    배경지식을 충분히 공부했음에도 문제 접근이 힘들면 컴퓨팅적 사고력이 부족한 것   

---
---
## 4. 알고리즘 설계 패러다임
---
### 1. 무식하게 풀기
전산학에서 '무식하게 푼다(brute-force)'는 말은 컴퓨터의 빠른 계산 능력을 이용해 **가능한 경우의 수를 일일이 나열하면서 답을 찾는 방법**을 의미  
이렇게 **가능한 방법을 전부 만들어 보는 알고리즘들**을 가리켜 **완전 탐색(exhaustive search)** 이라고 부름  

#### 재귀호출
컴퓨터가 수행하는 많은 작업들은 작은 조각으로 나눌 수 있음  
범위가 작아지면 작아질수록 각 조각들의 형태가 유사해지는 작업들을 많이 볼 수 있음  
완전히 같은 코드를 반복해 실행하는 for 같은 반복문이 좋은 예  

이런 작업을 구현할 때 유용하게 사용되는 개념이 **재귀 함수** 혹은 **재귀 호출**  

자신이 수행할 작업을 유사한 형태의 여러 조각으로 쪼갠 뒤 그 중 한 조각을 수행하고,  
나머지를 자기 자신을 호출해 실행하는 함수를 가리킴  

```
코드 6.1 1부터 n까지의 합을 계산하는 반복 함수와 재귀 함수
// 필수 조건 : n >= 1
// 결과 : 1부터 n까지의 합을 반환
int sum(int n){
    int ret = 0;
    for(int i = 1; i <= n; ++i;)
        ret += i;
    return ret;
}

// 필수 조건 : n >= 1
// 결과 : 1부터 n까지의 합을 반환
int recursiveSum(int n){
    if(n == 1)  return 1; // 더이상 쪼개지지 않을 때
    return n + recursiveSum(n-1);
}
```
n개의 숫자의 합을 구하는 작업을 n개의 조각으로 쪼개, 더할 각 숫자가 하나의 조각이 되도록 함  
재귀 호출을 이용하기 위해서는 이 조각 중 하나를 떼내어 자신이 해결하고, 나머지 조각들은 자기 자신을 호출해 해결해야 함  

모든 재귀 함수는 '더이상 쪼개지지 않는' **최소한의 작업에 도달했을 때 답을 곧장 반환하는 조건문을 포함**해야함  
이렇게 쪼개지지 않는 가장 작업들을 가리켜 재귀 호출의 **기저 사례(base case)** 라고 함  

기저 사례를 선택할 때는 **존재하는 모든 입력이 항상 기저 사례의 답을 이용해 계산될 수 있도록** 신경써야 함  

재귀 호출은 문제의 특성에 따라 코딩을 훨씬 간편하게 해 줄 수 있는 강력한 방법이 되기도 함  

#### 예제 : 중첩 반복문 대체하기
0번부터 차례대로 번호 매겨진 n개의 원소 중 네 개를 고르는 모든 경우를 출력하는 코드  
```
for(int i = 0; i < n; i++)
    for(int j = i+1; j < n; j++)
        for(int k = j+1; k < n; k++)
            for(int l = k+1; l < n; l++)
                cout << i << " " << j << " " << k << " " << l << endl;
```
위 예제는 4중 for문을 쓰면 되나, 다섯 개를 고른다면 5중 for문을, 여섯 개면 6중 for문을...  
골라야 할 원소의 수가 늘어날수록 코드가 길고 복잡해지고, 골라야 할 원소의 수가 입력에 따라 달라질 수 있는 경우에는 사용할 수 없다는 문제가 있음  

재귀 호출은 이런 경우에 단순한 반복문보다 간결하고 유연한 코드를 작성할 수 있도록 해줌  

위 코드 조각이 하는 작업은 네 개의 조각으로 나눌 수 있음  
각 조각에서 하나의 원소를 고르는 것  
이렇게 원소를 고른 뒤, 남은 원소들을 고르는 작업을 자기 자신을 호출해 떠넘기는 재귀 함수를 작성함  
이때 남은 원소들을 고르는 '작업'을 다음과 같은 입력들의 집합으로 정의할 수 있음

- 원소들의 총 개수
- 더 골라야 할 원소들의 개수
- 지금까지 고른 원소들의 번호

#### 코드 6.2
```
코드 6.2 n개의 원소 중 m개를 고르는 모든 조합을 찾는 알고리즘
// n : 전체 원소의 수
// picked : 지금까지 고른 원소들의 번호
// toPick : 더 고를 원소의 수
// 일 때, 앞으로 toPick개의 원소를 고르는 모든 방법을 출력함
void pick(int n, vector<int>& picked, int toPick){
    // 기저 사례 : 더 고를 원소가 없을 때 고른 원소들을 출력
    if(toPick == 0) { printPicked(picked); return; }

    // 고를 수 있는 가장 작은 번호를 계산
    int smallest = picked.empty() ? 0 : picked.back() + 1;

    // 이 단계에서 원소 하나를 고름
    for(int next = smallest; next < n ; next++){
        picked.push_back(next);
        pick(n, picked, toPick - 1);
        picked.pop_back();
    }
}
```

#### 예제 : 보글 게임
보글(Boggle)은 5x5 크기의 알파벳 격자를 가지고 하는 게임  
hasWord(y, x, word) = 보글 게임판의 (y, x)에서 시작하는 단어 word의 존재 여부를 반환  

이 문제를 풀 때 가장 까다로운 점은 다음 글자가 될 수 있는 칸이 여러 개 있을 때 이 중 어느 글자를 선택해야 할지 미리 알 수 없다는 것  
이를 해결하는 간단한 방법은 완전 탐색을 이용해, 단어를 찾아낼 때까지 모든 인접한 칸을 하나씩 시도해 보는 것  
그중 한칸에서라도 단어를 찾을 수 있다면 성공, 없다면 실패  

#### 기저 사례의 선택  
더 이상의 탐색 없이 간단히 답을 낼 수 있는 다음 경우들을 기저 사례로 선택함
1. 위치 (y, x)에 있는 글자가 원하는 단어의 첫 글자가 아닌 경우 항상 실패
2. (1번 경우에 해당되지 않을 경우) 원하는 단어가 한 글자인 경우 항상 성공  

두 조건 간의 순서가 바뀌면 안됨  

#### 간결한 코드를 작성하는 유용한 팁
입력이 잘못되거나 범위에서 벗어난 경우도 기저 사례로 택해서 맨 처음에 처리하는 것이 좋음  
그러면 함수를 호출하는 시점에 이런 오류를 검사할 필요가 없음  
재귀 함수는 항상 한군데 이상에서 호출되기 때문에, 이 습관은 반복적인 코드를 제거하는 데 큰 도움이 됨  

```
코드 6.3 보글 게임판에서 단어를 찾는 재귀 호출 알고리즘
const int dx[8] = {-1, -1, -1, 1, 1, 1, 0, 0};
const int dy[8] = {-1, 0, 1, -1, 0, 1, -1, 1};

// 5x5의 보글 게임 판의 해당 위치에서 주어진 단어가 시작하는 지를 반환
bool hasWord(int y, int x, const string& word){
    // 기저 사례 1 : 시작 위치가 범위 밖이면 무조건 실패
    if(!inRange(y, x))  return false;
    // 기저 사례 2 : 첫 글자가 일치하지 않으면 실패
    if(board[y][x] != word[0])  return false;
    // 기저 사례 3 : 단어 길이가 1이면 성공
    if(word.size() == 1)    return true;
    
    // 인접한 여덟 칸을 검사
    for(int direction = 0; direction < 8; direction++){
        int nextY = y + dy[direction], nextX = x + dx[direction];
        // 다음 칸이 범위 안에 있는지, 첫 글자는 일치하는지 확인할 필요가 없음 -> 기저 사례로 검사
        if(hasWord(nextY, nextX, word.substr(1)))
            return true;
    }
    return false;
}
```

#### 시간 복잡도 분석
완전 탐색 알고리즘의 시간 복잡도를 계산하는 것은 비교적 단순  
완전 탐색은 가능한 답 후보들을 모두 만들어 보기 때문에, 시간 복잡도를 계산하기 위해서는 가능한 후보의 수를 전부 세어 보기만 하면 됨  
이를 위해서는 후보의 최대 수를 계산하면 됨  

예를 들어 A로 가득찬 격자에서, 단어 AAAAAH를 찾는다고 할 때,  
모든 후보들을 빠짐없이 검사하면서 단어의 끝에 도달해서야 답을 찾을 수 없다는 것을 알게 됨  
이때, 검사하게 되는 후보의 수는 각 칸에 최대 여덟 개의 이웃이 있고, 탐색은 단어의 길이 N에 대해 N-1단계 진행됨  
따라서 검사하는 후보의 수는 최대 $8^{N-1} = O(8^N)$이 되고, 이것이 이 알고리즘의 시간 복잡도가 됨  

이 문제에서 후보의 수는 단어의 길이에 따라 지수적으로 증가하기 때문에 단어의 길이가 짧은 경우에만 완전 탐색으로 해결할 수 있음  

#### 재귀 호출과 부분 문제
- 주어진 자연수 수열을 정렬하라  
- {16, 7, 9, 1, 31}을 정렬하라  
얼핏 보면 같은 문제라고 할 수 있지만, 전자는 특정한 입력을 지정하지 않은 반면, 후자는 특정한 입력을 지정하기 때문  
재귀 호출을 논의할 때 '문제'란 항상 수행해야 할 작업과 그 작업을 적용할 자료의 조합을 의미  

보블 게임에서 문제는 '게임판에서의 현재 위치(y, x) 그리고 단어 word가 주어질 때 해당 단어를 이 칸에서부터 시작해서 찾을 수 있는가?' 로 정의 됨  
이를 알기 위해서는 아홉 가지 정보를 알아야 함  
1. 현재 위치 (y, x)에 단어의 첫 글자가 있는가?
2. 윗 칸 (y-1, x)에서 시작해서, 단어의 나머지 글자들을 찾을 수 있는가?
3. 왼쪽 위 칸(y-1, x-1)에서 시작해서 단어의 나머지 글자들을 찾을 수 있는가?
4. ...
5. ...

이 중 2번 이후의 항목은 원래 문제에서 한 조각을 떼어냈을 뿐, 형식이 같은 또 다른 문제를 푼 결과  
문제를 구성하는 조각들 중 하나를 뺏기 때문에, 이 문제들은 원래 문제의 일부라고 할 수 있음  
이런 문제들을 원래 문제의 **부분 문제** 라고 함

#### 6.7 최적화 문제
답이 하나가 아니라 여러개이고, 그 중에서 어떤 기준에 따라 가장 '좋은' 답을 찾아 내는 문제를 **최적화 문제(Optimization problem)** 이라고 부름

예를 들어 n개의 원소 중에서 r개를 순서 없이 골라내는 문제는 원하는 답이 하나이기 때문에 최적화 문제가 아님  

하지만 n개의 사과 중에서 r개를 골라서 무게의 합을 최대화하는 문제,  
가장 무거운 사과와 가장 가벼운 사과의 무게 차이를 최소화하는 문제 등은 최적화 문제임  
(사과를 고르는 방법은 여러 가지, 이 중 특정 기준에 의해 가장 좋은 답을 고르는 문제이기 때문)  

최적화 문제를 해결하는 방법은 여러 가지이지만, 그 중 가장 기초적이고 직관적인 방법이 **완전 탐색**  

#### 예제: 여행하는 외판원 문제
가장 유명한 최적화 문제  

어떤 나라에 n(2 <= n <= 10)개의 도시가 있다고 할 때, 한 영업 사원이 한 도시에서 출발해 다른 도시들을 전부 한 번씩 방문한 뒤 시작 도시로 돌아온다고 할 때 가장 짧은 경로를 찾아내야함  

#### 무식하게 풀 수 있을까?
완전 탐색으로 문제를 풀기 위한 첫 번째 단계는 시간 안에 답을 구할 수 있을지 확인하는 것  

어디서 시작하든 n-1개의 도시를 나열하는 방법이 이 문제를 완전탐색 하는 방법의 수와 동일함  
n-1개의 도시를 나열하는 방법은 모두 (n-1)!가지가 있음  

도시가 열 개라면 경로의 수는 9! = 362,880개가 됨  
큰 수처럼 보이나 컴퓨터가 1초 안에 가볍게 처리할 수 있는 숫자이기 때문에 완전 탐색을 이용할 수 있음  

#### 재귀 호출을 통한 답안 생성
n개의 도시로 구성된 경로를 n개의 조각으로 나눠, 앞에서부터 도시를 하나씩 추가해 경로를 만들어가면 됨  

```
코드 6.7 여행하는 외판원 문제를 해결하는 재귀 호출 알고리즘
int n; // 도시의 수
double dist[MAX][MAX]; // 두 도시 간의 거리를 저장하는 배열

// path : 지금까지 만든 경로
// visited : 각 도시의 방문 여부
// currentLength : 지금까지 만든 경로의 길이
// 나머지 도시들을 모두 방문하는 경로들 중 가장 짧은 것의 길이를 반환
double shortestPath(vector<int>& path,vector<bool>& visited, double currentLength){
    // 기저 사례 : 모든 도시를 다 방문했을 때는 시작 도시로 돌아가고 종료
    if(path.size() == n)
        return currentLength + dist[path[0]][path.back()];

    double ret = INF; // 매우 큰 값으로 초기화
    
    // 다음 방문할 도시를 전부 시도
    for(int next = 0; next < n; next++){
        if(visited(next))   continue;
        int here = path.back();
        path.push_back(next);
        visited[next] = true;
        
        // 나머지 경로를 재귀 호출을 통해 완성하고 가장 짧은 경로의 길이를 얻음
        double cand = shortestPath(path, visited, currentLength + dist[here][next]);

        ret = min(ret, cand);
        visited[next] = false;
        path.pop_back();
    }

    return ret;
}
```

#### 6.10 많이 등장하는 완전 탐색 유형
주어진 원소로 만들 수 있는 모든 순열 만들기, 주어진 원소 중 R개를 골라낼 수 있는 방법 만들기 등 다른 문제의 부분 문제로도 빈번히 출제됨  
입력의 크기에 따라 답의 개수가 어떻게 변하는지를 알고 구현하는 방법을 연습해 두면 좋음  

- 모든 순열 만들기  
    서로 다른 N개의 원소를 일렬로 줄 세운 것을 **순열(permutation)** 이라고 부름  

    순열을 생성해서 풀 수 있는 문제는 꽤 자주 나오고, 다른 문제의 부분 문제로 나타나기도 함  
따라서 모든 순열을 생성하는 코드를 한 번 신경써서 작성해 보면 좋음  

    가능한 순열의 수는 N이 되는데, N이 10을 넘어간다면 시간 안에 모든 순열을 생성하기 어려우므로 다른 방법을 생각해야함  

    C++에서는 STL에 포함된 next_permutation() 함수에서 모든 순열을 순서대로 생성하는 작업을 할 수 있음  

- 모든 조합 만들기  
    서로 다른 N개의 원소 중에서 R개를 순서 없이 골라낸 것을 **조합(Combination)** 이라고 부름  

    앞에서 본 [코드 6.2](#-코드-6.2)가 재귀 호출로 구현한 좋은 예  

- $2^n$ 가지 경우의 수 만들기  
    n개의 질문에 대한 답이 예/아니오 중 하나라고 할 때, 존재할 수 있는 답의 모든 조합의 수는 $2^n$가지  

    각 조합을 하나의 n비트 정수 표현한다고 생각하면 재귀 호출을 사용할 것 없이 1차원 for문 하나로 이 조합들을 간단하게 모두 시도할 수 있음

### 2. 분할 정복

### 3. 동적 계획법
동적 계획법은 큰 의미에서 분할 정복과 **같은 접근 방식**을 의미  
동적 계획법과 분할 정복의 **차이**가 발생하는 부분은 **문제를 나누는 방식**  

동적 계획법에서 어떤 부분 문제는 두 개 이상의 문제를 푸는데 사용될 수 있기 때문에, 이 문제의 답을 여러 번 계산하는 대신 한 번만 계산하고 계산 결과를 **재활용**함으로써 속도의 향상을 꾀할 수 있음  
그러기 위해서는 각 문제의 답을 메모리에 저장해야 함  
이 때 이미 계산한 값을 저장해 두는 메모리의 장소를 **캐시(cache)** 라고 부르며,  
두 번 이상 계산되는 부분 문제를 중복되는 부분 문제(overlapping subproblems)라고 부름  

동적 계획법 알고리즘의 가장 유명한 예 중 하나는 이항 계수의 계산임  
이항 계수 $(^n_r)$ 은 n개의 서로 다른 원소 중에서 r개의 원소를 순서없이 골라내는 방법의 수를 나타낸 것으로,  
다음과 같은 점화식이 성립함  
$(^n_r) = (^{n-1}_{r-1}) + (^{n-1}_r)$  
이 점화식을 이용하면 n, r의 값이 주어질 때 $(^n_r)$의 값을 반환하는 함수 bino(n, r)를 아래와 같이 작성 가능

```
코드 8.1 재귀 호출을 이용한 이항 계수의 계산
int bino(int n, int r){
    // 시저 사례 : n = r(모든 원소를 다 고르는 경우) 혹은 r = 0(고를 원소가 없는 경우)
    if(r == 0 || n == r)    return 1;
    return bino(n-1, r-1) + bino(n-1, r);
}
```
여기서 bino(2, 1)는 bino(3, 1)을 계산하기 위해서도 필요하고 bino(3, 2)를 계산하는데도 필요함  
함수의 중복 호출 수는 n과 r이 커짐에 따라 기하급수적으로 증가함  
bino(25, 12)를 계산하기 위해서는 천만 번의 함수 호출이 필요함  

n과 r이 정해져있을 때 bino(n, r)의 반환 값이 일정하다는 사실을 이용해 중복을 제거 할 수 있음  

각 n, r 조합에 대해 답을 저장하는 캐시 배열을 만들어서 각 입력에 대한 반환 값을 저장함  
```
코드 8.2 메모이제이션을 이용한 이항 계수의 계산
// -1로 초기화해 둠
int cache[30][30];
int bino2(int n, int r){
    // 기저 사례
    if(r == 0 || n == r)    return 1;
    // -1이 아니라면 한 번 계산했던 값이니 곧장 반환
    if(cache[n][r] != -1)
        return cache[n][r];
    // 직접 계산한 뒤 배열에 저장
    return cache[n][r] = bino2(n-1, r-2) + bino2(n-1, r);
}
```
위와 같이 함수의 결과를 저장하는 장소를 마련해 두고, 한 번 계산한 값을 저장해 뒀다 재활용하는 최적화 기법을 **메모이제이션(memoization)** 이라고 부름

이와 같이 두 번 이상 반복 계산되는 부분 문제들의 답을 미리 저장함으로써 속도의 향상을 꾀하는 알고리즘 설계 기법을 동적 계획법이라고 함  

#### 메모이제이션을 적용할 수 있는 경우
수학의 함수에서는 입력이 정해져 있을 때 출력도 정해져 있음  
하지만 프로그래밍을 할 때는 이런 속성들이 성립하지 않음  
함수의 입력 외에도, 전역 변수, 입력 파일, 클래스의 멤버 변수 등 수많은 입력에 의해 작동되기 때문  

따라서 메모이제이션은 입력이 고정되어 있을 때 그 결과가 항상 같은 함수인 참조적 투명 함수의 경우에만 적용 가능  

#### 메모이제이션 구현 패턴
(한 가지 패턴을 정해두고 항상 같은 형태로 구현하면 작성하기도, 버그 찾기도 쉬워짐)  
1. 항상 기저 사례를 제일 먼저 처리  
    입력이 범위를 벗어난 경우 등을 기저 사례로 처리하면 매우 유용  
    기저 사례를 먼저 확인하지 않고 cache[] 에 접근하면 범위를 벗어나는 등의 오류가 있을 수 있음  

2. 함수의 반환 값이 항상 0 이상이라는 점을 이용해 cache[]를 모두 -1로 초기화  
    반환 값이 음수일 수도 있다면 이 방법은 사용할 수 없음  

3. ret가 cache[a][b]에 대한 참조형(reference)임  
    참조형 ret의 값을 바꾸면 cache[a][b]의 값도 변하기 때문에 답을 저장할 때도 cache[a][b]를 다시 쓸 필요가 없음  
    이는 cache가 다차원 배열일 때 유용함, 실수를 할 가능성을 없애 줌  

```
코드 8.3 메모이제이션의 사용 예
// 전부 -1로 초기화해 둠
int cache[2500][2500];

// a와 b는 각각[0, 2500] 구간 안의 정수
// 반환 값은 항상 int형 안에 들어가는 음이 아닌 정수
int someObscureFunction(int a, int b){
    // 기저 사례를 처음에 처리
    if(...) return ...;
    
    // (a, b)에 대한 답을 구한 적이 있으면 곧장 반환
    int& ret = cache[a][b];
    if(ret != -1) return ret;

    // 여기서 답 계산
    ...
    return ret;
}
```

---
---
## 5. 유명한 알고리즘들
---
### 1. 정수론
#### 소수
소수(prime number)는 양의 약수가 1과 자기 자신 두 개 뿐인 자연수를 의미  
주어진 수가 소수인지 아닌지 판별하는 것은 소수에 관련된 가장 기초적인 문제  

주어진 수 n이 소수인지 판단하는 가장 단순한 방법은 2부터 n-1까지의 모든 수를 순회하면서 이 중 n의 약수가 있는지 확인하는 것  
거기에 합성수 n이 p X q로 표현될 때 한 수는 항상 √n 이하, 다른 한 수는 항상 √n 이상이라는 점을 이용하면  
n-1까지 순회하지 않고 √n 까지만 순회하도록 최적화할 수 있음  

```
// 주어진 자연수 n이 소수인지 확인
bool isPrime(int n){
    // 예외 처리 : 1과 2는 예외로 처리
    // 2가 유일한 짝수 소수이기 때문에 2만 예외 처리하면 그 외의 모든 짝수는 합성수
    if(n <= 1) return false;
    if(n == 2) return true;
    // 2를 제외한 모든 짝수는 소수가 아님
    if(n % 2 == 0) return false;
    // 2를 제외했으니 3이상의 모든 홀수로 나누어봄
    int sqrtn = int(sqrt(n));
    for(int div = 3; div <= sqrtn; div += 2)
        if(n % div == 0)    return false;
    return true;
}
```

#### 소인수 분해
소인수 분해는 한 합성수를 소수들의 곱으로 표현하는 방법(prime factorization)  
소인수 분해를 하는 가장 쉬운 방법은 소수 판별 알고리즘을 응용하는 것  
2부터 시작해 n의 소인수가 될 수 있는 수들을 하나하나 순회하면서 n의 약수를 찾을 때마다 n을 이 숫자로 나눔  
이 알고리즘은 n이 소수인경우 √n 번 반복문을 돌기 때문에 시간 복잡도는 O(√n)이 됨  
```
// 주어진 정수 n을 소인수분해하는 간단한 알고리즘
vector<int> factorSimple(int n){
    vector<int> ret;
    int sqrtn = int(sqrt(n));
    for(int div = 2; div <= sqrtn; ++div){
        while(n % div == 0){
            n /= div;
            ret.push_back(div);
        }
    }
    if(n > 1) ret.push_back(n);
    return ret;
}
```

소수인 div로만 n을 나누려 시도하는 대신 [2, √n] 범위의 모든 정수로 시도한다는 것을 눈여겨 봐야함  
만약 div가 합성수라면 n은 div의 소인수들로 최대한 나눠진 뒤이기 때문에, n이 div로 나눠질 일은 없음

소인수 분해를 최적화할 수 있는 방법 중 하나는 처리해야 할 입력의 최대값 MAX에 대해 √MAX까지의 소수들을 미리 찾아두는 것  
그러면 소수들로만 n을 나눠볼 수 있기 때문에 훨씬 빨라짐

#### 에라토스테네스의 체(Sieve of Eratosthenes)
프로그래밍 대회에서 소수 관련 문제를 풀 때 가장 자주 사용되는 방법

에라토스테네스의 체는 2부터 n까지의 수를 쭉 쓴 상태에서 지워지지 않은 수들을 순회하며 이 수의 배수를 지우기를 반복함  
사실상 앞에서 다룬 간단한 소수 판별 알고리즘을 [2, n] 범위의 모든 자욘수에 대해 확장한 것  
단, 각 수 m이 소수인지 판단하기 위해 √m까지의 모든 수로 나눠보는 대신, 소수를 찾을 때마다 그 배수들을 지우는 형태로 동작하기 때문에 훨씬 빠름  
```
int n;
bool isPrime[MAX_N+1];
// 가장 단순한 형태의 에라토스테네스의 체의 구현
// 종료한 뒤 isPrime[i] = i가 소수인가?
void eratosthenes(){
    memset(isPrime, 1, sizeof(isPrime));
    // 1은 항상 예외 처리
    isPrime[0] = isPrime[1] = false;
    int sqrtn = int(sqrt(n));
    for(int i = 2; i <= sqrtn; ++i){
        // 이 수가 아직 지워지지 않았다면
        if(isPrime[i])
            // i의 배수 j들에 대해 isPrime[j] = false로 둠
            // i * i 미만의 배수는 이미 지워졌으므로 신경쓰지 않음
            for(int j = i*i; j <= n; j += i)
                isPrime[j] = false;
    }
}
```

#### 유클리드 알고리즘(Euclidean algorithm)
두 수의 최대공약수를 구하는 방법  
유클리드 알고리즘은 두 수 p, q(p > q)의 공약수 집합은 p-q와 q의 공약수 집합과 같다는 점을 이용  
따라서 p, q의 최대공약수 gcd(p, q)는 항상 p-q와 q의 최대 공약수 gcd(p-q, q)와 같음
```
int gcd(int p, int q){
    if(p < q)   swap(p, q);
    if(q == 0)  return p;
    return gcd(p-q, q);
}
```

gcd(1024, 6)를 호출 했다고 하면  
gcd(1024, 6) = gcd(1018, 6) = gcd(1012, 6) = gcd(1006, 6) = ... 으로   
재귀 호출은 gcd(4, 6)이 호출될 때까지 계속 될 것임  
이를 빠르게 돌리는 방법은 p에서 q를 빼는 대신 p를 q로 나눈 나머지를 취하면 됨  
```
int gcd(int p, int q){
    if(q == 0)  return p;
    return gcd(q, p % q);
}
```

p < q 일 때에 대한 처리를 따로 하지 않은 이유는  
p < q인 입력이 들어올 경우 p % q = p 이므로 다음 재귀 호출 때 자동으로 gcd(q, p)가 되기 때문  

#### 모듈라 연산(modular arithmetic)
모듈로(modulus) M에 도달하면 다시 0으로 돌아가는 정수들을 가지고 하는 연산  
모듈라 연산에서 모든 정수는 M으로 나눈 나머지로 표현됨  

모듈라 연산은 무한히 큰 정수를 다룰 수 없는 컴퓨터의 특성 때문에 프로그램 대회에 종종 출현함  
64비트 정수형으로도 표현할 수 없는 큰 정수를 다뤄야 하는 문제의 경우,  
답을 직접 계산하는 대신 어떤 수 P로 나눈 나머지를 계산하기를 요구함

#### 모듈라 덧셈, 뺄셈, 그리고 곱셈
정수 a, b를 M으로 나눈 나머지가 각각 a', b'라고 할 때 a + b를 M으로 나눈 나머지는 얼마일까?  
a = xM + a', b = yM + b'라고 하면 a + b = (x + y)M + (a' + b) 가 되므로  
이 수를 M으로 나누면 그 나머지는 결국 (a' + b') % M이 됨  

다시 말해 두 수를 더한 뒤 나머지를 취하는 것은 미리 두 수의 나머지를 구한 뒤 더하고, 다시 나머지를 취하는 것과 같음  

이와 같은 속성은 덧셈, 뺄셈, 그리고 곱셈에 모두 성립함
 - (a + b) % M = ((a % M) + (b % M)) % M
 - (a - b) % M = ((a % M) - (b % M) + M) % M
 - (a X b) % M = ((a % M) X (b % M)) % M

#### 모듈라 나눗셈
이와 같은 일반적인 공식은 나눗셈에서는 성립하지 않음  

모듈라 연산에서의 나눗셈 a / b는 b로 나누는 대신 b의 곱셈 역원을 곱하는 방식으로 이루어짐  
b의 곱셈 역원은 항상 존재하는 것이 아니라, b가 M과 서로소일 때만 존재함  
이를 돌려 말하면 '나누어 떨어지지 않는다'와 비슷한 개념으로 생각할 수 있음  

프로그래밍 대회에 출제되는 대부분의 문제에서는 M이 소수인데, 이 경우에 b의 역원 modInv(b, M)은 다음과 같이 정의됨  

`modInv(b, M) = b<sup>M-2</sup> % M`  

따라서 (a / b) % M을 다음과 같이 계산할 수 있음  

`(a / b) % M = (a X modInv(b, M)) % M`

---
## 7. 트리
---
### 1. 트리의 구현과 순회
#### 트리
계층적 구조를 갖는 자료들을 표현하기 위한 자료 구조  
현실 세계의 개념을 추상화해 표현하는 자료 구조로 고안되었지만, 탐색형 자료 구조로도 유용하게 쓰임(작업 속도가 빠름)  

#### 트리의 표현
```
struct TreeNode {
    string label;   // 저장할 자료(문자열은 예시)
    TreeNode* parent;   // 부모 노드를 가리키는 포인터
    vector<TreeNode*> chilren;  // 자손 노드들을 가리키는 포인터의 배열
}
```
이 객체 *TreeNode*는 특정 구조나 형태를 가정하지 않음  
즉, 어떤 형태의 트리라도 트리의 가장 기초적인 조건을 충족하기만 한다면 표현할 수 있다는 뜻

#### 트리의 순회
트리는 구조가 일정하지 않기 때문에 포함된 모든 자료들을 순회하기가 어려움  
이와 같은 일을 쉽게 하기 위해서는 **트리의 재귀적 속성**을 이용해야함  
모든 트리는 각 자식들을 루트로 하는 서브트리와 루트로 나눌 수 있으므로, 트리의 루트가 주어질 때 루트를 방문한 뒤 각 서브트리를 재귀적으로 방문하는 함수를 만들어 트리의 모든 노드를 순회할 수 있음
```
// 주어진 트리의 각 노드에 저장된 값을 모두 출력
void printLabels(TreeNode* root){
    // 루트에 저장된 값을 출력
    cout << root->label << endl;
    // 각 자손들을 루트로 하는 서브트리에 포함된 값들을 재귀적으로 호출
    for(int i = 0; i < root->children.size(); i++)
        printLables(root->children[i]);
}
```

트리의 순회에는 O(n)의 시간이 들음

### 2. 이진 검색 트리
**검색 트리**는 연결 리스트나 큐처럼 자료들을 담는 컨테이너지만, 자료들을 일정한 순서에 따라 **정렬한 상태**로 저장해 둠  

이진 검색 트리에서는 각 노드의 왼쪽 서브트리에는 해당 노드의 원소보다 작은 원소를 가진 노드들이, 오른쪽에는 큰 원소를 가진 노드들이 들어감  
이진 검색 트리를 중위 순회하면 크기 순서로 정렬된 원소의 목록을 얻을 수 있음  
이진 검색 트리는 집합에 원소를 추가하거나 삭제하는 **조작 연산**을 할 때 강력함

#### 트립
> 구현이 간단한 균형잡힌 이진 검색 트리  

입력이 특정 순서로 주어질 때 성능이 떨어진다는 이진 검색 트리의 단점을 해결하기 위해 고안된 일종의 **랜덤화된 이진 검색 트리**  
트립은 이진 검색 트리와 같은 성질을 가지고 있지만 트리의 형태가 원소들의 추가 순서에 따라 결정되지 않고 난수에 의해 임의대로 결정됨  
때문에 원소들이 어느 순서대로 추가되고 삭제되더라도 **트리 높이의 기대치**는 **항상 일정**  
이와 같은 속성을 유지하기 위해 트립은 새 노드가 추가될 때마다 해당 노드에 우선순위를 부여 *(이 우선순위는 난수를 통해 생성)*  
트립은 항상 부모의 우선 순위가 자식의 우선순위보다 높은 이진 검색 트리를 만듬 *(힙과도 같은 성질, 힙(heap)과 트리(tree)의 성질을 모두 가지고 있어서 트립(treap))*  
그렇기 때문에 트립의 조건은 다음 두 가지로 정리 가능
 - 이전 검색 트리의 조건 : 모든 노드에 대해 왼쪽 서브트리에 있는 노드들의 원소는 해당 노드의 원소보다 작고, 오른쪽 서브트리에 있는 노드들의 원소는 해당 노드의 원소보다 큼
 - 힙의 조건 : 모든 노드의 우선순위는 각자의 자식 노드보다 크거나 같음

```
typedef int KeyType;
// 트립의 한 노드를 저장
struct Node{
    // 노드에 저장된 원소
    KeyType Key;
    // priority : 이 노드의 우선순위
    // size : 이 노드를 루트로 하는 서브트리의 크기
    int priority, size;
    // 두 자식 노드의 포인터
    Node *left, *right;
    // 생성자에서 난수 우선순위를 생성하고, size와 left / right를 초기화
    Node(const KeyType& _Key) : key(_key), priority(rand()), size(1), left(NULL), right(NULL) {}
    void SetLeft(Node* newLeft) { left = newLeft; calcSize(); }
    void SetRight(Node* newRight) { right = newRight; calcSize(); }
    // size 멤버를 갱신
    void calcSize(){
        size = 1;
        if(left) size += left->size;
        if(right) size += right->size;
    }
}
```

k번째 원소 찾기
이진 검색 트리를 직접 작성하는 것은 표준 라이브러리의 구현에서 제공하지 않는 기능이 필요할 때  
그 중 하나가 주어진 서브트리의 노드들을 포함한 원소의 크기 순으로 나열했을 때 k번째로 오는 노드를 찾는 연산  
Node 클래스는 서브트리의 크기 size를 계산해 저장해 두기 때문에 이것을 구현하기 어렵지 않음
 - k <= l : k번째 노드는 왼쪽 서브트리에 속해 있음
 - k = l+1 : 루트가 k번재 노드
 - k > l+1 : k번째 노드는 오른쪽 서브트리에서 k - l - 1번째 노드가 됨

 ```
 // root를 루트로 하는 트리 중에서 k번째 원소를 반환
 Node* kth(Node* root, int k){
     // 왼쪽 서브트리의 크기를 우선 계산
     int leftSize = 0;
     if(root->left != NULL) leftSize = root->left->size;
     if(k <= leftSize) return kth(root->left, k);
     if(k == leftSize + 1) return root;
     return kth(root->right, k - leftSize - 1);
 }
 ```

### 3. 우선순위 큐와 힙
#### 우선순위 큐
큐와 유사하나 가장 먼저 입력된 자료가 가장 먼저 꺼내지는 것이 아닌,   
**우선순위**가 가장 높은 자료가 가장 먼저 꺼내지는 큐  
균현 잡힌 이진 검색 트리를 사용하면 원소를 찾아 삭제하는 일과 새 원소를 삽입하는 일을 모두 O(logN) 시간에 할 수 있으나, 이는 단순한 작업에 어울리지 않음  
따라서 더욱 단순한 구조로 우선순위 큐를 구현할 필요가 있음

#### 힙
이에 적합한 것이 **힙(heap)**  
힙은 가장 큰 원소를 찾는 것에 최적화된 형태의 이진 트리  
새 원소를 추가하는 연산과 가장 큰 원소를 꺼내는 연산을 모두 O(logN) 시간에 수행 가능  
대부분의 프로그래밍 언어의 표준 라이브러리에 포함되어 있기 때문에 직접 구현할 일이 거의 없음

힙이 갖는 가장 중요한 규칙은 부모 노드가 가진 원소는 항상 자식 노드가 가진 원소 이상이라는 것, 이를 **힙의 대소 관계 규칙**이라고 부름  
힙에서 대소 관계 규칙은 부모 자식 관계에만 적용되며, 왼쪽 자식과 오른쪽 자식이 갖는 원소의 크기는 제한하지 않음  

트리가 한쪽으로 기울어지는 일을 막기 위해서 힙 또한 트리의 구조에 제한을 둠
 - 마지막 레벨을 제외한 모든 레벨에 노드가 꽉 차있어야 함
 - 마지막 레벨에 노드가 있을 때는 항상 가장 왼쪽부터 순서대로 채워져 있어야 함  

이러한 엄격한 모양 규칙은 구현할 때 장점으로 작용함  
 - A[i]에 대응되는 노드의 왼쪽 자손은 A[2 x i + 1]에 대응됨
 - A[i]에 대응되는 노드의 오른쪽 자손은 A[2 x i + 2]에 대응됨
 - A[i]에 대응되는 노드의 부모는 A[(i - 1) / 2]에 대응됨(나눗셈 결과는 내림)
 
힙의 모양 규칙에 의해 힙에 n개의 노드가 있을 때 이 노드들은 A[0]에서 A[n-1]까지 순차적으로 대응함

#### 새 원소의 삽입
힙의 모든 조건을 유지하면서 새 원소를 삽입 할 때 여러 번거로움을 피할 수 있는 방법은 대소 관계 규칙 대신 모양 규칙을 먼저 만족시키는 것  
모양 규칙에 의해 새 노드는 항상 heap[]의 맨 끝에 추가한 후 힙의 대소 관계 속성을 만족시키기는 간단함  
마지막에 추가한 새 원소를 자신의 부모 노드가 가진 원소와 비교하고, 부모 노드가 가진 원소가 작다면 두 원소의 위치를 바꿈. 새 원소가 더 크거나 같은 원소를 가진 부모 노드를 만나거나 루트에 도달할 때까지 반복
```
// 정수를 담는 최대 힙 heap에 새 원소 newValue를 삽입 
void push_heap(vector<int>& heap, int newValue){
    // 힙의 맨 끝에 newValue를 추가
    heap.push_back(newValue)

    // 현재 newValue의 위치
    int idx = heap.size() - 1;

    // 루트에 도달하거나 newValue 이상의 원소를 가진 조상을 만날 때까지
    while(idx > 0 && heap[(idx - 1) / 2] < heap[idx]){
        swap(heap[idx], heap[(idx - 1) / 2]);
        idx = (idx - 1) / 2;
    }
}
```

#### 최대 원소 꺼내기
배열을 이용해 구현한 최대 힙에서 최대 원소는 배열의 첫 원소를 확인하면 됨  
문제는 최대 원소를 힙에서 꺼내는 일, 힙의 엄격한 모양 제한 때문에 구현이 까다로움  
새 원소의 삽입과 같이 모양 규칙을 충족하는 힙을 먼저 만든 뒤 대소 관계 규칙을 만족하도록 조작하면 좀 더 간단하게 구현 가능  
힙의 모양 구조에 의해 힙의 마지막에 있는 노드는 어차피 지워질 것임, 따라서 이 노드를 일단 지우고 시작함  
*(이 노드는 리프이기 때문에 노드가 지워져도 힙의 구조에는 영향을 끼치지 않음)*  
마지막 노드에 있던 원소를 루트에 덮어 씌우면 힙의 모양 규칙은 만족시킴  

이후에 힙의 대소 관계 조건을 만족시키기 위해 루트가 두 자식이 가지고 있던 원소 중 큰 쪽이 루트에 올라와야하기 때문에, 두 자식 노드가 가진 원소 중 큰 원소와 맞바꿈  
그리고 이 작업을 트리의 바닥에 도달하거나, 두 자손이 모두 자기 자신 이하의 원소를 갖고 있을 때까지 반복하면 됨
```
// 정수를 담는 최대 힙 heap에서 heap[0]을 제거
void pop_heap(vector<int>& heap){
    // 힙의 맨 끝에서 값을 가져와 루트에 덮어씌움
    heap[0] = heap.back();
    heap.pop_back();
    int here = 0;
    while(true){
        int left = here * 2 + 1, right = here * 2 + 2;
        // 리프에 도달한 경우
        if(left >= heap.size()) break;
        // heap[here]가 내려갈 위치를 찾음
        int next = here;
        if(heap[next] < heap[left])
            next = left;
        if(right < heap.size() && heap[next] < heap[right])
            next = right;
        if(next == here) break;
        swap(heap[here], heap[next]);
        here = next;
    }
}
```

### 4. 구간 트리
구간 트리는 흔이 일차원 배열의 특정 구간에 대한 질문을 빠르게 대답하는데 사용함  
구간 최소 쿼리(range minimum query, RMQ)라고 불리는 특정 구간의 최소치를 찾는 문제는 구간 트리의 예 중 하나  
```
(0, 14)
(0, 7)                                        | (8, 14)
(0, 3)                | (4, 7)                | (8, 11)                 | (12, 14)
(0, 1)    | (2, 3)    | (4, 5)    | (6, 7)    | (8, 9)    | (10, 11)    | (12, 13)    | (14)
(0) | (1) | (2) | (3) | (4) | (5) | (6) | (7) | (8) | (9) | (10) | (11) | (12) | (13) | (14)
```
↑ 길이 15인 배열을 표현하는 구간 트리가 저장하는 구간들  

#### 구간 트리의 표현
구간 트리는 비교적 **'꽉 찬' 이진 트리**임  
꽉 찬 이진 트리는 포인터로 연결된 객체를 표현하기보다는 **배열로 표현하는 것**이 메모리를 더 절약할 수 있음  
루트 노드를 배열의 1번 원소로, 노드 i의 왼쪽 자손과 오른쪽 자손을 각각 2 x i와 2 x i + 1번 원소로 표현  
이 배열의 길이는 가장 가까운 2의 거듭제곱으로 n을 올림한 뒤 2를 곱하거나 그냥 n에 4를 곱해도 됨(메모리는 손해)

#### 구간 트리의 초기화
```
// 배열의 구간 최소 쿼리를 해결하기 위한 구간 트리의 구현
struct RMQ{
    // 배열의 길이
    int n;
    // 각 구간의 최소치
    vector<int> rangeMin;
    RMQ(const vector<int>& array){
        n = array.size();
        rangeMin.resize(n * 4);
        init(array, 0, n-1, 1);
    }
}
// node 노드가 array[left..right] 배열을 표현할 때
// node를 루트로 하는 서브트리를 초기화하고, 이 구간의 최소치를 반환
int init(const vector<int>& array, int left, int right, int node){
    if(left == right)
        return rangeMin[node] = array[left];
    int mid = (left + right) / 2;
    int leftMin = init(array, left, mid, node * 2);
    int rightMin = init(array, mid + 1, right, node * 2 + 1);
    return rangeMin[node] = min(leftMin, rightMin);
}
```
위의 코드는 RMQ 문제를 해결하는 RMQ 클래스의 구조와 각 노드마다 해당 구간의 최소치를 계산하는 함수 init()을 구현한 것  
구간 트리의 각 노드에 대해 위치 등을 저장해 두지 않음  
(해당 노드를 찾아가는 과정에서 표현하는 구간을 동적으로 계산할 수 있기 때문에 저장하지 않아도 됨)  

#### 구간 트리의 질의 처리
초기화를 했으면 임의의 구간의 최소치를 구할 준비가 된 것  
이것을 구간 트리에서의 질의(query) 연산 이라고 부름  
질의 연산은 구간 트리에서의 순회를 응용해 간단하게 구현 가능  

    query(left, right, node, nodeLeft, nodeRight) = node가 표현하는 범위 [nodeLeft, nodeRight]와 우리가 최소치를 찾기 원하는 구간 [left, right]의 교집합의 최소 원소를 반환

- 교집합이 공집합인 경우  
    두 구간은 서로 겹치지 않음, 따라서 반환 값음 존재하지 않음.  
    반환 값이 무시되도록 아주 큰 값을 반환
- 교집합이 [nodeLeft, nodeRight]인 경우  
    [left, right]가 노드가 표현하는 집합을 완전히 포함하는 경우  
    이 노드에 미리 계산해 둔 최소치를 곧장 반환하면 됨
- 이 외의 모든 경우  
    두 개의 자손 노드에 대해 query()를 재귀 호출한 뒤, 이 두 값 중 더 작은 값을 택해 반환

```
const int INT_MAX = numeric_limits<int>::max();
struct RMQ{
    // ..생략..
    // node가 표현하는 범위 array[nodeLeft..nodeRight]가 주어질 때
    // 이 범위와 array[left..right]의 교집합의 최소치를 구함
    int query(int left, int right, int node, int nodeLeft, int nodeRight){
        // 두 구간이 겹치지 않으면 아주 큰 값을 반환 : 무시됨
        if(right < nodeLeft || nodeRight < left)    return INT_MAX;
        // node가 표현하는 범위가 array[left..right]에 완전히 포함되는 경우
        if(left <= nodeLeft && nodeRight <= right)  return rangeMin[node];
        // 양쪽 구간을 나눠서 푼 뒤 결과를 합침
        int mid = (nodeLeft + nodeRight) / 2;
        return min(query(left, right, node*2, nodeLeft, mid), 
                   query(left, right, node*2+1, mid+1, nodeRight));
    }
    // query()를 외부에서 호출하기 위한 인터페이스
    int query(int left, int right){
        return query(left, right, 1, 0, n-1);
    }
}
```

#### 구간 트리의 갱신
값이 하나 바뀔 때는 구간트리를 빠른 시간에 갱신할 수 있음  
갱신 과정은 query()와 init()을 합친 것 처럼 구현됨  
해당 노드가 표현하는 구간에 index가 포함되지 않는다면 그냥 무시되고, 포함된다면 재귀 호출해해서 두 자손 구간의 최소치를 계산한 뒤 다시 최소치를 구해 주면 됨
```
struct RMQ {
    // .. 생략 ..
    // array[index] = newValue로 바뀌었을 때 node를 루트로 하는
    // 구간 트리를 갱신하고 노드가 표현하는 구간의 최소치를 반환
    int update(int index, int newValue, int node, int nodeLeft, int nodeRight){
        // index가 노드가 표현하는 구간과 상관없는 경우엔 무시
        if(index < nodeLeft || nodeRight > index)
            return rangeMin[node];
        // 트리의 리프까지 내려운 경우
        if(nodeLeft == nodeRight)   return rangeMin[node] = newValue;
        int mid = (nodeLeft + nodeRight) / 2;
        return rangeMin[node] = min(
            update(index, newValue, node*2, nodeLeft, mid)
            update(index, newValue, node*2+1, mid+1, nodeRight));
    }
    // update()를 외부에서 호출하기 위한 인터페이스
    int update(int index, int newValue){
        return update(index, newValue, 1, 0, n-1);
    }
}
```

#### 펜윅 트리 : 빠르고 간단한 구간 합
구간 트리의 가장 흔한 사용 예는 바로 구간 합을 빠르게 구하는 것 -> 펜윅 트리  
펜윅 트리가 사용하는 중요한 아이디어는 구간 합 대신 부분 합만을 빠르게 계산할 수 있는 자료구조를 만들어도 구간 합을 계산할 수 있다는 것  
(**부분 합**은 배열 A의 첫 몇 i개의 원소의 합, **구간 합**은 A의 연속된 부분 배열의 합,  
따라서 **부분 합은 첫 위치가 A[0]으로 고정된 구간 합**)  
배열 *A*의 위치 *pos*에 대해 부분 합 *psum*[*pos*] = *A*[0] + *A*[1] + ... + *A*[*pos*]를 빠르게 계산할 수 있다고 한다면, [*i*, *j*] 구간의 합은 *psum*[*j*] - psum[*i*-1]으로 계산할 수 있음
```
(0, 15)
(0, 7)                                        | (8, 15)
(0, 3)                | (4, 7)                | (8, 11)                 | (12, 15)
(0, 1)    | (2, 3)    | (4, 5)    | (6, 7)    | (8, 9)    | (10, 11)    | (12, 13)    | (14, 15)
(0) | (1) | (2) | (3) | (4) | (5) | (6) | (7) | (8) | (9) | (10) | (11) | (12) | (13) | (14) | (15)
```
> ↑ 길이 16인 배열의 구간 합을 구하기 위해 구간 트리를 계산해 저장하는 각 구간들  

이때 [8, 15] 구간의 구간 합은 사실 부분 합만을 구한다면 필요가 없음  
*psum*[15]를 구한다면 어차피 루트에 있는 값을 곧장 사용할 테고, 다른 위치의 부분 합을 구할 때는 이 값을 쓸 수 없기 때문  
이와 같은 원리로 하나의 긴 구간 밑에 두 개의 작은 구간이 있을 때 이 두 구간 중 오른쪽 구간은 항상 지워도 됨
```
(0, 15)
(0, 7)                                        | 
(0, 3)                |                       | (8, 11)                 | 
(0, 1)    |           | (4, 5)    |           | (8, 9)    |             | (12, 13)    |
(0) |     | (2) |     | (4) |     | (6) |     | (8) |     | (10) |      | (12) |      | (14) | 
```
> ↑ 필요한 부분만 남긴 결과  

남은 구간의 수는 정확하게 *n*개, 각 구간이 포함하는 오른쪽 끝 원소들을 보면 이들이 서로 모두 다름  
이 대응을 이용해 1차원 배열 하나에 각 구간의 합을 저장  
*A*[*pos*] 까지의 구간 합 *psum*[*pos*]를 계산하고 싶으면 *pos*에서 끝나는 구간의 합 *tree*[*pos*]를 답에 더하고, 남은 부분들을 왼쪽에서 찾아 더하면 됨  
`tree[i] = 위 결과에서 오른쪽 끝 위치가 A[i]인 구간의 합`

pos에서 끝나는 구간 다음으로 더해야 할 구간을 찾는 방법 → 이진수 표현 이용  
배열 *A*[]와 *tree*[]의 첫 원소의 인덱스를 1로 바꿈  
```
                                                                                    (16, 10000)
                                     (8, 1000)| 
              (4, 100)|                       |               (12, 1100)| 
   (2, 10)|           |   (6, 110)|           | (10, 1010) |             | (14,1110)   |
(1) |     | (3) |     | (5) |     | (7) |     | (9)  |     | (11) |      | (13) |      | (15) |
(1) |     | (11)|     |(101)|     |(111)|     |(1001)|     |(1011)|      |(1101)|      |(1111)|  
```
> ↑ 펜윅 트리에서 첫 원소의 인덱스를 1로 바꾼 결과  

오른쪽 끝 위치의 이진수 표현에서 마지막 비트를 지우면 다음 구간을 쉽게 찾을 수 있음  
예를 들어 *psum*[7]을 구하기 위해 *tree*[7], *tree*[6], *tree*[4]의 인덱스를 이진수 표현으로 보면 순서대로 111, 110, 100이 됨  
최종 비트를 지우기 위해서는 ***pos*-1과 비트별 AND**를 하면 됨  

펜윅 트리는 구간 트리처럼 모든 구간에 대해 답을 계산하지 않기 때문에 *O*(*n*)에 초기화하기가 불가능  
따라서 구간 트리의 갱신 연산처럼 **각 위치의 값을 변경하는 연산을 통해 내용을 채워넣어야 함**  

펜윅 트리에서 **배열의 값을 변경하는 것**은 **해당 위치의 값에 숫자를 더하고 빼는 것**으로 구현  
예를 들어 *A*[5]를 3 늘리고 싶다면 *A*[5]를 포함하는 모든 구간의 합들을 3씩 늘려주면 됨  
이때 늘려줘야 할 값들은 *tree*[5], *tree*[6], *tree*[8], *tree*[16]으로 각 인덱스의 이진수 표현은 101, 110, 1000, 10000임  
이는 **맨 오른쪽에 있는 1인 비트를 스스로에게 더해 주는 연산**을 반복하면 해당 위치를 포함하는 구간들을 모두 만날 수 있다는 것을 알 수 있음
```
// 펜윅 트리의 구현, 가상의 배열 A[]의 부분 합을
// 빠르게 구현할 수 있도록 함
// 초기화시에는 A[]의 원소가 전부 0이라고 생각
struct FenwickTree{
    vector<int> tree;
    FenwickTree(int n) : tree(n + 1) {}
    // A[0..pos]의 부분 합을 구함
    int sum(int pos){
        // 인덱스가 1부터 시작한다고 생각
        ++pos;
        int ret = 0;
        while(pos > 0){
            ret += tree[pos];
            // 다음 구간을 찾기 위해 최종 비트를 지움
            pos &= (pos - 1);
        }
        return ret;
    }
    // A[pos]에 val을 더함
    void add(int pos, int val){
        ++pos;
        while(pos < tree.size()){
            tree[pos] += val;
            pos += (pos & -pos);
        }
    }
};
```

 펜윅 트리의 구현은 엄청나게 간결하기 때문에 계속 변하는 배열의 구간 합을 구할 때는 구간 트리보다 펜윅 트리를 훨씬 자주 사용

### 5. 상호 배타적 집합
> 또 다른 형태의 독특한 트리로 상호 배타적 집합(disjoint set)을 표현할 때 쓰는 유니온-파인드(Union-Find) 자료 구조가 있음  
이 트리는 위의 트리들과 전혀 다른 용도로 사용되며, 전혀 다른 구조를 가지고 있음  

#### 상호 배타적 집합
어떤 파티에 n명의 사람들이 있을 때, 생일이 같은 사람들끼리 팀을 구성하라고 한다면  
처음에는 누가 자신과 생일이 같은지 모르기 때문에 모두 혼자 돌아다니다가 생일이 같은 사람을 한 번 찾으면 이 둘은 팀을 이뤄 같이 움직이게 됨  
그리고 다른 팀과 생일이 같다는 것을 확인하면 두 팀은 곧장 합쳐짐  
이러한 상황을 자료 구조로 표현한 것이 상호 배타적 집합  

**공통 원소가 없는, 상호 배타적인 부분 집합들로 나눠진 원소들에 대한 정보**를 저장하고 저장하는 자료 구조가 **유니온-파인드**  

이 상황을 표현하기 위해서 각 사람을 0부터 n-1까지의 원소로 표현, 각 1개의 원소를 포함하는 n개의 집합을 만듬  
그리고 두 사라람 a와 b가 서로 생일이 같다는 사실을 알 때마다 집합을 합침  
이와 같은 일들을 구현하기 위해 다음과 같은 세 가지 연산이 필요  
 - 초기화 : n개의 원소가 각각의 집합에 포함되어 있도록 초기화
 - 합치기(union) 연산 : 두 원소 a, b가 주어질 때 이들이 속한 두 집합을 하나로 합침
 - 찾기(find) 연산 : 어떤 원소 a가 주어질 때 이 원소가 속한 집합을 반환

#### 배열로 상호 배타적 집합 표현하기
상호 배타적 집합들을 표현하는 가장 간단한 방법은 **1차원 배열 하나**를 이용하는 것  

`belongsTo[i] = i번 원소가 속하는 집합의 번호`  

처음에 belongsTo를 각자 다른 숫자로 초기화하면 찾기 연산을 상수 시간에 구할 수 있음  
하지만 이 경우 합치기 연산을 수행할 때 *O*(*n*)의 시간이 걸림(모든 원소를 순환해야 하기 때문)  
따라서 찾기 연산에 시간이 좀 더 걸리더라도 합치기 연산을 빠르게 할 수 있는 방법이 필요  

#### 트리를 이용한 상호 배타적 집합의 표현
**한 집합에 속하는 원소들**을 **하나의 트리**로 묶어 줌  
두 원소가 같은 트리에 속해 있는지 확인하는 방법은 **각 원소가 포함된 트리의 루트**를 찾은 뒤 이들이 같은지 비교하는 것  
따라서 이 트리에서 찾기 연산은 주어진 원소가 포함된 **트리의 루트를 찾는 것**으로 구현  
이런 찾기 연산을 구현하기 위해서는 모든 자식 노드가 부모에 대한 포인터를 **가지고 있어야함**  
반면 부모에서 자식으로 내려갈 일은 없기 때문에 부모는 자식에 대한 포인터를 **가지고 있을 필요가 없음**  

이와 같이 트리를 이용한 집합 표현에서는 합치기도 아주 간단함  
각 트리의 루트를 찾은 뒤, 하나를 다른 한쪽의 자손으로 넣으면 됨

```
// 트리를 이용해 상호 배타적 집합을 구현
struct NaiveDisjointSet{
    vector<int> parent;
    NaiveDisjointSet(int n) : parent(n){
        for(int i = 0; i < n; ++i)
            parent[i] = i;
    }
    // u가 속한 트리의 루트의 번호를 반환
    int find(int u) const{
        if(u == parent[u])  return u;
        return find(parent[u]);
    }
    // u가 속한 트리와 v가 속한 트리를 합침
    void merge(int u, int v){
        u = find(u);    v = find(v);
        // u와 v가 이미 같은 트리에 속하는 경우를 걸러냄
        if(u == v) return;
        parent[u] = v;
    }
};
```

#### 상호 배타적 집합의 최적화
트리를 하용하여 합치기 연산을 할 때 루트 하나의 정보만 바꾸면 됨  
하지만 연산 순서에 따라 잘못하면 트리가 한쪽으로 기울어질 수 있다는 문제가 있음  
이를 해결하기 위해 두 트리를 합칠 때 항상 높이가 더 낮은 트리를 더 높은 트리 밑에 집어넣음으로써 트리의 높이가 높아지는 상황을 방지할 수 있음
```
// 트리를 이용해 상호배제적 집합을 구현
struct OptimizedDisjointSet{
    vector<int> parent, rank;
    OptimizedDisjointSet(int n) : parent(n), rank(n, 1){
        for(int i = 0; i < n; ++i)
            parent[i] = i;
    }
    // u가 속한 트리의 루트의 번호를 반환
    int find(int u) const{
        if(u == parent[u])  return u;
        return find(parent[u]);
    }
    // u가 속한 트리와 v가 속한 트리를 합침
    void merge(int u, int v){
        u = find(u);    v = find(v);
        // u와 v가 이미 같은 집합에 속하는 경우를 걸러냄
        if(u == v) return;
        if(rank[u] > rank[v]) swap(u, v);
        // 이제 rank[v]가 항상 rank[u] 이상이므로 u를 v의 자식으로 넣음
        parent[u] = v;
        if(rank[u] == rank[v]) ++rank[v];
    }
}
```

간단해보이지만 이 최적화만으로도 find() 연산에 드는 시간을 *O*(*N*) 에서 *O*(*logN*)으로 만들 수 있음  

많은 경우에는 이와 같은 최적화만으로도 충분하지만, 간단하면서 효과가 큰 다른 최적화 방법이 있음  
find(u)를 u가 속하는 트리의 루트를 찾아냈을 때, parent[u]를 찾아낸 루트로 야예 바꿔버리면 다음번에 find(u)가 호출되었을 때는 바로 루트를 찾을 수 있음  
이러한 최적화를 **경로 압축(path compression) 최적화**라고 부름

상호 배타적 집합이 하는 일은 많은 경우 그래프나 다른 자료 구조로도 할 수 있지만, 구현이 매우 간단하고 동작 속도가 아주 빠르기 때문에 다른 알고리즘의 일부로 사용되는 경우가 많음

---
## 8. 그래프
---

### 1. 그래프의 표현과 정의
계층 구조를 표현하기 위해 고안된 트리보다 좀 더 일반적이고 강력한 자료 구조인 그래프(graph)  
그래프는 현실 세계의 사물이나 추상적인 개념 간의 연결 관계를 표현  

#### 그래프의 정의
**그래프** G(V, E)는 **어떤 자료나 개념을 표현하는 정점(vertex)** 들의 집합 V와 **이들을 연결하는 간선(edge)** 들의 집합 E로 구성된 자료 구조  
그래프는 정점들과 간선들로 정의되며, 정점의 위치 정보나 간선의 순서 등은 그래프의 정의에 포함되지 않음

#### 그래프의 종류
그래프의 정의는 간단하나, 그래프는 표현하고자 하는 대상에 따라 여러 가지 변형됭 형태를 가질 수 있음  
정점이나 간선에 추가적인 속성을 부여할 수도 있고, 존재할 수 있는 간선이나 정점의 형태에 제약을 두기도 함  

그 중 대표적인 것으로 **방향 그래프(directed graph)** 혹은 **유향 그래프** 가 있음  
방향 그래프는 **간선이 방향이라는 새로운 속성** 을 가짐  
방향이 없는 그래프는 **무향 그래프(undirected graph)** 라고 부름  

다른 중요한 개념으로 **가중치 그래프(weighted graph)** 가 있음  
가중치 그래프는 **각 간선에 가중치(weight)** 라고 불리는 실수 속성을 부여

그래프의 **형태로 그래프를 분류**하는 경우도 있음  
**다중 그래프(multigraph)** 는 두 정점 사이에 **두 개 이상의 간선** 이 있을 수 있는 그래프  
반대로 두 정점 사이에 **최대 한 개의 간선** 만 있는 그래프를 **단순 그래프(simple graph)** 라고 부름  

**트리 혹은 루트 없는 트리(unrooted tree)** 는 부모 자식 관계가 없을 뿐, 간선들의 연결 관계만 보면 **트리와 같은 무향 그래프** 를 말함  

**이분 그래프(bipartite graph)** 는 그래프의 정점들을 겹치지 않는 두 개의 그룹으로 나눠서 **서로 다른 그룹에 속한 정점들 간에만 간선이 존재**하도록 만들 수 있는 그래프  

한 그래프가 앞에 이야기한 **두 가지 이상의 속성을 함께 가지는 경우**도 있음  
그중 중요한 것은 **사이클 없는 방향 그래프(directed acyclic graph)** 가 있음  
줄여서 DAG라고 부르는 이 그래프는 방향 그래프인데, 한 점에서 출발해 자기 자신으로 돌아오는 경로(사이클)가 존재하지 않는 경우를 말함  
DAG는 여러 작업들 간의 산호 의존 관계 등을 그래프로 표현할 때 흔하게 출현

#### 그래프의 경로
경로(path)란 서로 연결된 간선들을 순서대로 나열한 것  
경로 중 한 정점을 최대 한 번만 지나는 경로를 단순 경로(simple path)라고 부름  
시작한 점에서 끝나는 경로를 사이클(cycle) 혹은 회로라고 부름

#### 그래프의 사용 예
 - 철도망의 안정성 분석
 - 소셜 네트워크 분석
 - 인터넷 전송 속도 계산
 - 한 붓 그리기
 - 외환 거래

#### 암시적 그래프 구조들
그래프 같은 형태를 갖는 구조가 아니라도 그래프를 통해서 표현하면 쉽게 해결할 수 있는 문제들  
 - 할 일 목록 정리
 - 15-퍼즐
 - 게임판 덮기
 - 회의실 배정

#### 그래프의 표현 방법
여러 객체들이 서로 연결되어 있다는 점에서 그래프는 트리와 별로 다를 것이 없음  
그러나 많은 경우 그래프는 트리에 비해 훨씬 정적인 용도로 사용됨  
보다 정적이라는 말은 새로운 정점이나 간선을 추가하고 삭제하는 일이 자주 일어나지 않는다는 의미  
따라서 대부분의 그래프는 구조의 변경이 어렵더라도 좀더 간단하고 메모리를 적제 차지하는 방법으로 구현  

- 인접 리스트 표현  
그래프의 각 정점마다 해당 정점에서 나가는 간선의 목록을 저장해서 그래프를 구현  
따라서 그래프는 각 정점마다 하나의 연결 리스트를 갖는 방식으로 구현됨  
`vector<list<int>> adjacent;`  
이 때 adjacent[i]는 정점 i와 간선을 통해 연결된 정점들의 번호를 저장하는 연결 리스트  
만약에 가중치 그래프 등 간선이 추가적 속성을 갖는 그래프라면 간선의 정보를 구조체나 pair를 사용하여 표현

- 인접 행렬 표현  
인접 리스트 표현의 큰 단점은 두 정점이 주어질 때 이 정점이 연결되어 있는지를 알기 위해서는 연결 리스트를 일일이 뒤져야 한다는 것  
이와 같은 연산의 속도를 높이기 위해 고안된 그래프 표현 방식이 인접 행렬 표현 방식  
|V| x |V| 크기의 행렬, 즉 2차원 배열을 통해 그래프의 간선 정보를 저장  
`vector<vector<bool>> adjacent;`  
이 때 adjacent[i, j]는 정점 i에서 정점 j로 가는 간선이 있는지를 나타내는 불린 값 변수  
가중치 그래프를 인접 행렬로 표현하려면 각 간선의 정보를 정수나 실수 변수로 두고, 두 정점 사이에 간선이 없는 경우에는 이를 존재할 수 없는 값으로 지정하면 됨  

#### 인접 행렬 표현과 인접 리스트 표현의 비교  
- 인접 행렬 표현  
    - 정점의 번호 u, v가 주어졌을 때 두 정점을 잇는 간선이 있는지를 한 번의 배열 접근만으로 확인할 수 있음
    - |V| x |V| 크기의 2차원 배열을 사용하기 때문에, 실제 간선의 개수와 관계 없이 항상 O(|V|<sup>2) 크기의 공간을 사용

- 인접 리스트 표현
    - 간선(u, v)가 존재하는지 확인하기 위해서는 연결 리스트 adjacent[u]를 처음부터 읽어가면서 각원소를 일일이 확인해야 함
    - |V|개의 연결 리스트에 실제 간선 수만큼 원소가 들어 있으므로, O(|V| + |E|)의 공간만을 사용  
    (간혹 간선의 수가 |V|<sup>2에 비해 훨씬 적은 그래프를 희소 그래프(sparse graph),  
    반대로 간선의 수가 거의 |V|<sup>2에 비해 간선의 수가 훨씬 적은 밀집 그래프(dense pragh) 라고 함  
    따라서 희소 그래프에는 인접 리스트를, 밀집 그래프에는인접 행렬을 사용하는 것이 유리)

그래프의 어떤 표현 방식을 사용하느냐는 알고리즘의 시간 복잡도를 바꿀 수 있기 때문에 신중하게 선택해야 함

#### 암시적 그래프 표현
입력이 직접적으로 그래프 형태를 띠지 않는 문제의 경우 그래프 구조를 직접 사용하지 않고도 문제를 해결할 수 있는 경우가 자주 있음  
문제가 비교적 단순하여 일일이 입력을 그래프로 표현하기가 꽤나 번거롭거나, 그래프의 크기가 아주 큰데 실제로는 그중 일부만 사용하는 경우 암시적 그래프 표현이 유리함  
그렇다고 암시적 그래프 표현이 항상 더 좋은 것은 아님  
암시적 그래프 표현을 사용하면 그래프를 사용하는 알고리즘과 변환 과정이 합쳐지게 되고, 이 과정에서 코드가 더 복잡해지기 때문  
따라서 그래프에 대해 복잡한 연산이나 알고리즘을 수행할 거라면 번거롭더라도 입력을 미리 그래프 표현으로 바꿔 두는 것이 전체 코드를 간결하게 할 수 있음

### 2. 그래프의 깊이 우선 탐색(DFS)
트리의 순회와 같이 그래프의 모든 정점들을 특정한 순서에 따라 방문하는 알고리즘들을 그래프의 탐색 알고리즘이라고 함  
그래프는 트리보다 구조가 훨씬 복잡할 수 있기 때문에 탐색 과정에서 얻어지는 정보가 아주 중요함  
탐색 과정에서 어떤 간선이 사용되었는지, 또 어떤 순서로 정점들이 방문되었는지를 통해 그래프의 구조를 알 수 있음  

깊이 우선 탐색(depth-first search, DFS)은 현재 정점과 인접한 간선들을 하나씩 검사하다가, 아직 방문하지 않은 정점으로 향하는 간선이 있다면 그 간선을 무조건 따라가고, 이 과정에서 더 이상 갈 곳이 없는 막힌 정점에 도달하면 마지막에 따라왔던 간선을 따라 뒤로 돌아감  
이것을 구현하기 위해 지금까지 거쳐온 정점들을 모두 저장해 둬야 하는데, 재귀 호출을 이용하면  재귀 호출한 함수가 종료하면 호출한 위치로 다시 돌아간다는 점 때문에 간단하게 구현할 수 있음
```
// 그래프의 인접 리스트 순위
vector<vector<list>> adj;
// 각 정점을 방문했는지 여부를 나타냄
vector<bool> visited;
// 깊이 우선 탐색 구현
void dfs(int here){
    cout << "DFS visits " << here << end;
    visited[here] = true;
    // 모든 인접 정점을 순회하면서
    for(int i = 0; i < adj[here].size(); ++i){
        int there = adj[here][i];
        // 아직 방문한 적 없다면 방문
        if(visited[there])
            dfs(there);
    }
    // 더이상 방문할 정점이 없으니, 재귀 호출을 종료하고 이전 정점으로 돌아감
}
// 모든 정점을 방문
void afsAll(){
    // visited를 모두 false로 초기화
    visited = vector<bool>(adj.size(), false);
    // 모든 정점을 순회하면서, 아직 방문한 적 없으면 방문
    for(int i = 0; i < adj.size(); ++i)
        if(!visited[i])
            dfs(i);
}
```
그래프에����� 모든 정점들이 간선을 통해 연결되어 있다는 보장이 없기 때문에, dfs()만으로는 모든 정점을 순서대로 발견한다는 목적에 부합하지 않음  
대개 깊이 우선 탐색은 **그래프 전체의 구조를 파악**하기 위해 사용되므로 그래프의 구조상 한 번에 모든 정점을 다 볼 수 없는 경우에도 모든 정점을 다 방문할 필요가 있음  

#### 깊이 우선 탐색의 시간 복잡도
깊이 우선 탐색의 시간 복자도는 어떤 그래프 표현 방식을 사용하느냐에 따라 달라짐  
인접 리스트를 사용할 경우 dfs()는 한 정점마다 한 번씩 호출되므로, 정확히 |V|번 호출됨  
모든 정점에 대해 dfs()를 수행하고 나면 모든 간선을 정확히 한 번(방향 그래프의 경우) 혹은 두 번(무향 그래프의 경우) 확인함을 알 수 있기 때문에 깊이 우선 탐색의 시간 복잡도는 O(|V| + |E|)가 됨  

행렬을 사용하는 경우에도 dfs()의 호출 횟수는 |V|  
다만 행렬의 경우 다른 모든 정점을 순회하며 두 정점 사이에 간선이 있는가를 확인해야 하기 때문에 한 번의 실행에 O(|V|)의 시간이 걸림  
따라서 전체 시간 복잡도는 O(|V|)<sup>2가 됨

#### 깊이 우선 탐색 예
 - 두 정점이 서로 연결되어 있는가 확인
 - 연결된 부분집합의 개수 세기
 - 위상 정렬 : 의존성이 있는 작업들이 주어질 때, 이들을 어떤 순서로 수행해야 하는지 계산

#### 오일러 서킷
그래프의 모든 간선을 정확히 한 번씩 지나서 시작점으로 돌아오는 경로를 찾는 문제  

시작점을 u, 끝점을 v라고 할 때
- u ≠ v 인 경우, v에 인젛반 간선의 수는 항상 홀수, 나가는 데 하나의 간선 필요
- u = v 인 경우, v에 인접한 간선의 수는 항상 짝수, u에서 나가는 것으로 시작했으니, 들어온 뒤 다시 나갈 수 없음  

한 정점에 인접한 간선의 수를 해당 정점의 **차수(drgree)**라고 부름  
차수가 짝수인 정점을 짝수점, 홀수인 점을 홀수점으로 부름  

오일러 서킷의 존재 가능성에 더욱 직접적인 영향을 미치는 것은 **홀수점**  
오일러 서킷은 모든 정점에 들어가는 횟수와 나오는 횟수가 같아야 하는데, 홀수점이라면 이와 같은 일이 불가능 하기 때문  
따라서 **그래프의 모든 정점들이 짝수점이어야만** 오일러 서킷이 존재할 수 있음  

#### 오일러 서킷을 찾아내는 알고리즘  
어떤 그래프의 모든 정점이 짝수점이고, 모든 간선이 하나의 컴포넌트에 포함되어 있다고 할 때,  
임의의 정점 u에서 시작해 아직 따라가지 않은 간선 중 하나를 따라가며 임의의 경로를 만드는 함수 **findRandomCircuit(u)**  

이 함수는 현재 정점에 인접한 간선 중 아직 따라간 적 없는 임의의 간선을 따라가기를 반복하다가,  
더 이상 따라갈 간선이 없을 때 종료함  

findRandomCircuit()이 찾는 경로의 끝점은 그래프의 모든 정점이 짝수점이므로, 시작점 외의 다른 정점에서 종료하는 것은 불가능함  

아직 따라가지 않은 간선이 남아 있는 정점을 v라고 할 때,  
원래 v 또한 짝수점이었기 때문에 처음에 찾은 경로가 v를 지나가면서 짝수 개의 간선을 사용했고,  
짝수 개의 간선이 남을 수 밖에 없음  
따라서 v에서 시작하도록 findRandomCircuit()을 다시 수행하면 새로운 하나의 서킷을 얻게 됨  
그리고 두 서킷을 합치면 하나의 큰 서킷을 쉽게 만들 수 있음  

이런 방법을 곧이 곧대로 구현하기는 까다로움, 하지만 깊이 우선 탐색을 응용한 구현을 이용하면 쉽게 구현 가능  
findRandomCircuit()을 깊이 우선 탐색처럼 재귀 호출로 구현한다면  

findRandomCircuit(u)는 u와 인접한 간선들을 하나하나 검사하면서, 아직 방문하지 않은 간선(u, v)가 있다면 또 다시 findRandomCircuit(v)를 호출함  
그리고 더이상 따라갈 간선이 없다면 재귀 호출을 종료하고 반환함  
재귀 호출을 종료하는 순간, 지금까지 따라온 간선들을 모으면 하나의 서킷이 됨  

임의의 서킷을 찾은 후 각 정점을 순회하면서 아직 지나지 않은 간선이 남아있는지 확인해야 함  
재귀 호출의 반환 과정에서 해당 정점에 아직 간선이 남아 있는지를 확인하고, 남아 있다면 새 서킷을 만들어 가운데 끼워넣을 수 있음
```
// 그래프 인접 행렬 표현, adj[i][j] = i 와 j 사이의 간선의 수
vector<vector<int>> adj;
// 무향 그래프의 인접 행렬 adj가 주어질 때 오일러 서킷을 계산
// 결과로 얻어지는 circuit를 뒤집으면 오일러 서킷이 됨
void getEulerCircuit(int here, vector<int>& circuit){
    for(int there = 0; there < adj[here].size(); ++there){
        while(adj[here][there] > 0){
            adj[here][there]--; // 양쪽 간선을 모두 지움
            adj[there][here]--;
            getEulerCircuit(there, circuit);
        }
    }
    circuit.push_back(here);
}
```

각 간선을 따라갈 때 경로에 추가하는 것이 아니라 재귀 호출이 끝나고 반환할 때 추가하기 때문에  
서킷의 가운데에 끼워넣는 코드가 필요 없음  
결과적으로 circuit에는 경로의 끝점부터 역순으로 간선들이 추가됨  

각 간선을 따라갈 때마다 getEulerCircuit() 함수를 호출하고, 그 내부에서는 O(|V|)의 반복문을 수행하기 때문에  
이 알고리즘의 전체 시간 복잡도는 O(|V||E|)가 됨  
인접 리스트 표현을 쓰면 이것을 O(|E|)로 할 수 있찌만, 반대쪽에서 오는 간선을 지우는 구현이 까다로워 짐

#### 오일러 트레일
오일러 서킷처럼 그래프의 모든 간선을 정확히 한 번 지나지만,  
시작점과 끝점이 다른 경로를 **오일러 트레일(Eulerian trail)** 이라고 함  

주어진 그래프에서 오일러 트레일을 찾는 문제는 간단하게 오일러 서킷을 찾는 문제로 변환할 수 있음

점 a에서 시작해서 b에서 끝나는 옹일러 트레일을 찾고 싶다고 할 떄, a와 b사이에 간선 (b, a)를 추가한 뒤 오일러 서킷을 찾음  
그리고 (b, a) 간선을 지워서 서킷을 끊으면 오일러 트레일을 얻을 수 있음  
따라서 오일러 트레일의 존재 조건은 시작점과 끝점을 잇는 간선을 하나 추가한 뒤 모든 점이 짝수점이 되려면, **시작점과 끝점을 제외한 모든 점은 짝수점이고 시작점과 끝점은 홀수점**이어야 함

#### 방향 그래프에서의 오일러 서킷
방향 그래프에서 오일러 서킷을 찾는 알고리즘은 무향 그래프에서와 거의 다르지 않지만,  
오일러 서킷의 존재 조건이 무향 그래프와 다름  

오일러 서킷의 모든 점에서는 경로가 들어온 횟수와 나간 횟수가 같아야 함  
방향 그래프에서 각 간선은 둘 중 한 방향으로만 쓸 수 있기 때문에, 각 정점에 들어오는 간선의 수와 나가는 간선의 수가 같아야함  
나머지 조건들은 무향 그래프와 같음

방향 그래프에서 오일러 트레일의 존재 조건도 마찬가지임  
a에서는 나가는 간선이 들어오는 간선보다 하나 많고, b는 들어오는 간선이 나가는 간선보다 하나 많고, 다른 모든 정점에서는 나가는 간선과 들어오는 간선의 수가 같아야함

방향 그래프에서 오일러 서킷 혹은 트레일을 찾아내기
```
// 유향 그래프의 인접 행렬 adj가 주어질 때 오일러 서킷 혹은 트레일을 계산
void getEulerCircuit(int here, vector<int>& circuit){
    for(int there = 0; there < adj.size(); ++there){
        while(adj[here][there] > 0){
            adj[here][there]--;
            getEulerCircuit(there, circuit);
        }
    }
    circuit.push_back(here);
}
// 현재 그래프의 오일러 트레일이나 서킷을 반환
vector<int> getEulerTrailOrCircuit(){
    vector<int> circuit;
    // 우선 트레일을 찾아봄 : 시작점이 존재하는 경우
    for(int i = 0; i < 26; ++i){
        if(outdegree[i] == indegree[i] + 1){
            getEulerCircuit(i, circuit);
            return circuit;
        }
    }
    // 아니면 서킷이니, 간선에 인접한 아무 정점에서나 시작
    for(int i = 0; i < 26; ++i){
        if(outdegree[i]){
            getEulerCircuit(i, circuit);
            return circuit;
        }
    }
    // 모두 실패한 경우 빈 배열을 반환
    return circuit;
}
```

#### DFS 이론적 배경과 운용
깊이 우선 탐색을 수행하면 그 과정에서 그래프의 모든 간선을 한 번씩은 만나게 되는데  
탐색이 따라가는 간선만 모아보면 트리 형태를 띠게 됨  
이런 트리를 DFS 스패닝 트리라고 부름  

그래프의 DFS스패닝 트리를 생성하고나면 그래프의 모든 간선을 다음 네 가지 중 하나로 분류 가능  
 - 트리 간선(tree edge) : 스패닝 트리에 포함된 간선
 - 순방향 간선(forward edge) : 스패닝 트리의 선조에서 자손으로 연결되지만 트리 간선이 아닌 간선
 - 역방향 간선(back edge) : 스패닝 트리의 자손에서 선조로 연결되는 간선
 - 교차 간선(cross edge) : 이 세가지 분류를 제외한 나머지 간선

무향 그래프의 모든 간선은 양방향으로 통행 가능하므로, 무향 그래프에는 교차 간선이 있을 수 없음  
또한 순방향 간선과 역방향 간선의 구분이 없음  

```
// 그,래프의 인접 리스트 표현
vector<vector<int>> adj;
// discovered[i] = i번 정점의 발견 순서
// finished[i] = dfs(i) 가 종료했으면 1, 아니면 0
vector<int> discovered, finished;
// 지금까지 발견한 정점의 수
int counter;
void dfs(int here){
    discovered[here] = counter++;
    // 모든 인접 정점을 순회
    for(int i = 0; i < adj[here].size(); ++i){
        int there = adj[here][i];
        // 아직 방문한 적 없다면 방문
        if(discovered[there] == -1){
            cout << "tree edge" << endl;
            dfs(there);
        }            
        // 만약 there가 here보다 늦게 발견됐으면 there는 here의 후손
        else if(discovered[here] < discovered[there])
            cout << "forward edge" << endl;
        // 만약 dfs(there)가 아직 종료하지 않았으면 there는 here의 선조
        else if(finished[there] == 0)
            cout << "back edge" << endl;
        // 이 외의 경우는 모두 교차 간선
        else
            cout << "cross edge" << endl;
    }
    finished[here] = 1;
}
```

### 3. 그래프 너비 우선 탐색(BFS)
너비 우선 탐색은 시작점에서 가까운 정점부터 순서대로 방문하는 탐색 알고리즘  

각 정점을 방문할 때마다 모든 인접 정점들을 검사  
이 중 처음 보는 정점을 발견하면 이 정점을 방문 예정이라고 기록해 둔 뒤, 별도의 위치에 저장  
인접한 정점을 모두 검사하고 나면, 지금까지 저장한 목록에서 다음 정점을 꺼내서 방문  
```
// 그래프의 인접 리스트 표현
vector<vector<int>> adj;
// start에서 시작해 그래프를 너비 우선 탐색하고 각 정점의 방문 순서를 반환
vector<int> bfs(int start){
    // 각 정점의 방문 여부
    vector<bool> discovered(adj.size(), false);
    // 방문할 정점 목록을 유지하는 큐
    queue<int> q;
    // 정점의 방문 순서
    vector<int> order;
    discovered[start] = true;
    q.push(start);
    while(!q.empty()){
        int here = q.front();
        q.pop();
        // here을 방문
        order.push_back(here);
        // 모든 인접한 정점을 검사
        for(int i = 0; i < adj[here].size(); ++i){
            int there = adj[here][i];
            // 처음 보는 정점이면 방문 목록에 집어 넣음
            if(!discovered[there]){
                q.push[there];
                discovered[there] = true;
            }
        }
    }
    return order;
}
```

BFS는 발견과 방문이 같지 않음, 따라서 모든 정점은 세 개의 상태를 순서대로 거쳐 가게 됨
 1. 아직 발견되지 않은 상태
 2. 발견되었지만 아직 방문되지는 않은 상태(큐에 저장된 상태)
 3. 방문된 상태

너비 우선 탐색에서 새 정점을 발견하는 데 사용했던 간선들만을 모은 트리를 BFS 스패닝 트리라고 부름  

#### 너비 우선 탐색의 시간 복잡도
DFS와 다를 것이 없음  
정점을 한 번씩 방문하며, 정점을 방문할 때마다 인접한 모든 간선을 검사하기 때문  
따라서, 인접 리스트로 구현된 경우 O(|V| + |E|), 인접 행렬로 구현했을 경우 O(|V|<sup>2)

#### 너비 우선 탐색과 최단 거리
그래프의 구조에 관련된 다양한 문제를 푸는 데 사용되는 DFS와 달리, BFS는 대개 그래프에서의 최단 경로 문제를 푸는 용도로 사용됨  

BFS 과정에서 간선 (u, v)를 통해 정점 v를 처음 발견해 큐에 넣었다고 할 때,  
시작점으로부터 v까지의 최단 거리 distance[v]는 시작점으로부터 u까지의 최단 거리 distance[u]에 1을 더한 것  

이 속성의 다른 중요한 의미는 시작점으로부터 다른 모든 정점까지의 최단 경로를 BFS 스패닝 트리 위에서 찾을 수 있음  
각 정점으로부터 트리의 루트인 시작점으로 가능 경로가 실제 그래프 상에서의 최단 경로임  
```
// start에서 시작해 그래프를 BFS하고 시작점부터 각 정점까지의 최단 거리와 BFS 스패닝 트리를 계산
// distance[i] = start부터 i까지의 최단 거리
// parent[i] = BFS 스패닝 트리에서의  i의 부모의 번호, 루트인 경우 자신의 번호
void bfs(int start, vector<int>& distance, vector<int>& parent){
    distance = vector<int>(adj.size(), -1);
    parent = vector<int>(adj.size(), -1);
    // 방문할 정점 목록을 유지하는 큐
    queue<int> q;
    distance[start] = 0;
    parent[start] = start;
    q.push(start);
    while(!q.empty()){
        int here = q.front();
        q.pop();
        // here의 모든 인접한 정점을 검사
        for(int i = 0; i < adj[here].size(); ++i){
            int there = adj[here][i];
            // 처음 보는 정점이면 방문 목록에 집어넣음
            if(distance[there] == -1){
                q.push(there);
                distance[there] = distance[here] + 1;
                parent[there] = here;
            }
        }
    }
}
// v로부터 시작점까지의 최단 경로를 계산
vector<int> shortestPath(int v, const vector<int>& parent){
    vector<int> path(1, v);
    while(parent[v] != v){
        v = parent[v];
        path.push_back(v);
    }
    reverse(path.begin(), path.end());
    return path;
}
```

BFS는 대개 시작점으로부터 다른 정점들까지의 거리를 구하기 위해 사용되기 때문에  
DFS처럼 모든 정점을 검사하면서 탐색을 수행하는 작업은 잘 하지않음




---
> 본 내용은 인사이트에서 출판한 '프로그래밍 대회에서 배우는 알고리즘 문제해결전략' 을 읽고 공부하며 작성하였습니다.